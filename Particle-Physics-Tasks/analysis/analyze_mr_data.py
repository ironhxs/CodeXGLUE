#!/usr/bin/env python3
"""
MR æ•°æ®åˆ†æè„šæœ¬ - åˆ†æçˆ¬å–çš„æ•°æ®ï¼Œç¡®å®šå¯è¡Œçš„è¯„ä¼°ä»»åŠ¡

ç”¨æ³•:
    python analyze_mr_data.py --data_dir=../Git_crawler1/mr_data
"""

import json
import os
import argparse
from pathlib import Path
from collections import defaultdict, Counter
import re


def load_mr_data(data_dir: str):
    """åŠ è½½æ‰€æœ‰ MR æ•°æ®"""
    mr_files = list(Path(data_dir).glob('mr_*.json'))
    mrs = []
    
    for f in mr_files:
        try:
            with open(f, 'r', encoding='utf-8') as fp:
                mrs.append(json.load(fp))
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•åŠ è½½ {f.name}: {e}")
    
    return mrs


def analyze_basic_stats(mrs):
    """åŸºç¡€ç»Ÿè®¡"""
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸºç¡€ç»Ÿè®¡")
    print("=" * 60)
    
    print(f"æ€» MR æ•°é‡: {len(mrs)}")
    
    # çŠ¶æ€ç»Ÿè®¡
    states = Counter(mr.get('state', 'unknown') for mr in mrs)
    print(f"MR çŠ¶æ€åˆ†å¸ƒ: {dict(states)}")
    
    # æ—¶é—´èŒƒå›´
    dates = [mr.get('created_at', '')[:10] for mr in mrs if mr.get('created_at')]
    if dates:
        print(f"æ—¶é—´èŒƒå›´: {min(dates)} ~ {max(dates)}")


def analyze_code_changes(mrs):
    """åˆ†æä»£ç å˜æ›´"""
    print("\n" + "=" * 60)
    print("ğŸ“ ä»£ç å˜æ›´åˆ†æ")
    print("=" * 60)
    
    total_changes = 0
    file_extensions = Counter()
    diff_lengths = []
    
    for mr in mrs:
        changes = mr.get('changes', [])
        total_changes += len(changes)
        
        for change in changes:
            # æ–‡ä»¶æ‰©å±•å
            path = change.get('new_path', '') or change.get('old_path', '')
            if '.' in path:
                ext = '.' + path.rsplit('.', 1)[-1]
                file_extensions[ext] += 1
            
            # Diff é•¿åº¦
            diff = change.get('diff', '')
            diff_lengths.append(len(diff))
    
    print(f"æ€»å˜æ›´æ–‡ä»¶æ•°: {total_changes}")
    print(f"å¹³å‡æ¯ä¸ª MR å˜æ›´æ–‡ä»¶æ•°: {total_changes / len(mrs):.1f}")
    
    print("\næ–‡ä»¶ç±»å‹åˆ†å¸ƒ (Top 10):")
    for ext, count in file_extensions.most_common(10):
        print(f"  {ext}: {count}")
    
    if diff_lengths:
        print(f"\nDiff é•¿åº¦: min={min(diff_lengths)}, max={max(diff_lengths)}, avg={sum(diff_lengths)/len(diff_lengths):.0f}")
    
    # ç‰©ç†ç›¸å…³æ–‡ä»¶
    physics_exts = ['.cpp', '.cxx', '.cc', '.C', '.h', '.hpp', '.py', '.cu']
    physics_count = sum(file_extensions.get(ext, 0) for ext in physics_exts)
    print(f"\nç‰©ç†ç›¸å…³æ–‡ä»¶ (C++/Python): {physics_count} ({physics_count/total_changes*100:.1f}%)")
    
    return file_extensions


def analyze_comments(mrs):
    """åˆ†æè¯„è®ºæ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ’¬ è¯„è®ºåˆ†æ")
    print("=" * 60)
    
    total_comments = 0
    non_system_comments = 0
    comment_lengths = []
    
    for mr in mrs:
        comments = mr.get('comments', [])
        total_comments += len(comments)
        
        for comment in comments:
            if not comment.get('system', False):
                non_system_comments += 1
                body = comment.get('body', '')
                comment_lengths.append(len(body))
    
    print(f"æ€»è¯„è®ºæ•°: {total_comments}")
    print(f"éç³»ç»Ÿè¯„è®ºæ•°: {non_system_comments}")
    print(f"å¹³å‡æ¯ä¸ª MR è¯„è®ºæ•°: {total_comments / len(mrs):.1f}")
    
    if comment_lengths:
        print(f"è¯„è®ºé•¿åº¦: min={min(comment_lengths)}, max={max(comment_lengths)}, avg={sum(comment_lengths)/len(comment_lengths):.0f}")
        
        # æœ‰æ•ˆè¯„è®ºï¼ˆé•¿åº¦ > 10ï¼‰
        valid_comments = sum(1 for l in comment_lengths if l > 10)
        print(f"æœ‰æ•ˆè¯„è®ºæ•° (é•¿åº¦>10): {valid_comments}")
    
    return non_system_comments, comment_lengths


def analyze_discussions(mrs):
    """åˆ†æè®¨è®ºæ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ—£ï¸ è®¨è®ºåˆ†æ")
    print("=" * 60)
    
    total_discussions = 0
    multi_turn = 0  # å¤šè½®å¯¹è¯
    qa_pairs = []   # é—®ç­”å¯¹
    
    for mr in mrs:
        discussions = mr.get('discussions', [])
        total_discussions += len(discussions)
        
        for disc in discussions:
            notes = disc.get('notes', [])
            if len(notes) > 1:
                multi_turn += 1
                # æå–é—®ç­”å¯¹
                first_note = notes[0].get('body', '')
                if '?' in first_note and len(notes) > 1:
                    qa_pairs.append({
                        'question': first_note,
                        'answer': notes[1].get('body', '')
                    })
    
    print(f"æ€»è®¨è®ºæ•°: {total_discussions}")
    print(f"å¤šè½®å¯¹è¯æ•°: {multi_turn}")
    print(f"æ½œåœ¨é—®ç­”å¯¹æ•°: {len(qa_pairs)}")
    
    return qa_pairs


def analyze_titles_descriptions(mrs):
    """åˆ†ææ ‡é¢˜å’Œæè¿°"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ ‡é¢˜/æè¿°åˆ†æ")
    print("=" * 60)
    
    title_lengths = [len(mr.get('title', '')) for mr in mrs]
    desc_lengths = [len(mr.get('description', '') or '') for mr in mrs]
    
    non_empty_desc = sum(1 for d in desc_lengths if d > 0)
    
    print(f"æ ‡é¢˜é•¿åº¦: min={min(title_lengths)}, max={max(title_lengths)}, avg={sum(title_lengths)/len(title_lengths):.0f}")
    print(f"æœ‰æè¿°çš„ MR: {non_empty_desc} ({non_empty_desc/len(mrs)*100:.1f}%)")
    
    if non_empty_desc > 0:
        valid_desc = [d for d in desc_lengths if d > 0]
        print(f"æè¿°é•¿åº¦: min={min(valid_desc)}, max={max(valid_desc)}, avg={sum(valid_desc)/len(valid_desc):.0f}")


def suggest_tasks(mrs, file_extensions, comment_count, qa_pairs):
    """æ ¹æ®æ•°æ®é‡å»ºè®®å¯è¡Œçš„ä»»åŠ¡"""
    print("\n" + "=" * 60)
    print("ğŸ¯ å¯è¡Œä»»åŠ¡å»ºè®®")
    print("=" * 60)
    
    n = len(mrs)
    
    print(f"\nåŸºäº {n} ä¸ª MR æ•°æ®:\n")
    
    # ä»»åŠ¡1: ä»£ç æ‘˜è¦
    if n >= 50:
        print("âœ… ä»»åŠ¡1: ä»£ç å˜æ›´æ‘˜è¦ç”Ÿæˆ")
        print(f"   æ•°æ®é‡: {n} ä¸ªæ ·æœ¬ (æ¯ä¸ªMRä¸€ä¸ª)")
        print("   æ¨è: Few-shot æˆ– Fine-tune (å¦‚æœ>500)")
    else:
        print("âš ï¸ ä»»åŠ¡1: ä»£ç å˜æ›´æ‘˜è¦ç”Ÿæˆ - æ•°æ®é‡ä¸è¶³")
    
    # ä»»åŠ¡2: è¯„è®ºç”Ÿæˆ
    if comment_count >= 100:
        print(f"\nâœ… ä»»åŠ¡2: ä»£ç å®¡æŸ¥è¯„è®ºç”Ÿæˆ")
        print(f"   æ•°æ®é‡: {comment_count} æ¡è¯„è®º")
    else:
        print(f"\nâš ï¸ ä»»åŠ¡2: ä»£ç å®¡æŸ¥è¯„è®ºç”Ÿæˆ - è¯„è®ºæ•°é‡ä¸è¶³ ({comment_count})")
    
    # ä»»åŠ¡3: ä»£ç è¡¥å…¨
    physics_exts = ['.cpp', '.cxx', '.cc', '.C', '.h', '.hpp', '.py']
    physics_files = sum(file_extensions.get(ext, 0) for ext in physics_exts)
    if physics_files >= 100:
        print(f"\nâœ… ä»»åŠ¡3: ç‰©ç†ä»£ç è¡¥å…¨")
        print(f"   æ•°æ®é‡: {physics_files} ä¸ªç‰©ç†ç›¸å…³æ–‡ä»¶")
    else:
        print(f"\nâš ï¸ ä»»åŠ¡3: ç‰©ç†ä»£ç è¡¥å…¨ - ç‰©ç†æ–‡ä»¶ä¸è¶³ ({physics_files})")
    
    # ä»»åŠ¡4: ä»£ç é—®ç­”
    if len(qa_pairs) >= 50:
        print(f"\nâœ… ä»»åŠ¡4: ä»£ç ç†è§£é—®ç­”")
        print(f"   æ•°æ®é‡: {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
    else:
        print(f"\nâš ï¸ ä»»åŠ¡4: ä»£ç ç†è§£é—®ç­” - é—®ç­”å¯¹ä¸è¶³ ({len(qa_pairs)})")
    
    # ä»»åŠ¡5: æ„å›¾åˆ†ç±»
    if comment_count >= 200:
        print(f"\nâœ… ä»»åŠ¡5: è¯„è®ºæ„å›¾åˆ†ç±»")
        print(f"   æ•°æ®é‡: {comment_count} æ¡è¯„è®º")
    else:
        print(f"\nâš ï¸ ä»»åŠ¡5: è¯„è®ºæ„å›¾åˆ†ç±» - è¯„è®ºä¸è¶³")
    
    print("\n" + "-" * 60)
    print("å»ºè®®ä¼˜å…ˆçº§:")
    if n >= 100:
        print("1. å…ˆåšä»£ç æ‘˜è¦ç”Ÿæˆï¼ˆæ•°æ®å……è¶³ï¼‰")
        print("2. å†åšæ„å›¾åˆ†ç±»ï¼ˆå¦‚æœè¯„è®ºè¶³å¤Ÿï¼‰")
        print("3. æœ€åå°è¯•ä»£ç è¡¥å…¨")
    else:
        print("1. æ•°æ®é‡è¾ƒå°‘ï¼Œå»ºè®®ä½¿ç”¨ few-shot è¯„ä¼°")
        print("2. æˆ–ç»§ç»­çˆ¬å–æ›´å¤šæ•°æ®")


def save_sample_data(mrs, output_dir):
    """ä¿å­˜æ ·æœ¬æ•°æ®ä¾›æ£€æŸ¥"""
    sample_file = Path(output_dir) / 'sample_data.json'
    
    if len(mrs) > 0:
        sample = mrs[0]
        with open(sample_file, 'w', encoding='utf-8') as f:
            json.dump(sample, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“„ æ ·æœ¬æ•°æ®å·²ä¿å­˜åˆ°: {sample_file}")


def main():
    parser = argparse.ArgumentParser(description='åˆ†æ MR æ•°æ®')
    parser.add_argument('--data_dir', required=True, help='MR æ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', default='.', help='è¾“å‡ºç›®å½•')
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ” MR æ•°æ®åˆ†æå·¥å…·")
    print("=" * 60)
    print(f"æ•°æ®ç›®å½•: {args.data_dir}")
    
    # æ£€æŸ¥ç›®å½•
    if not Path(args.data_dir).exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        print("è¯·å…ˆä½¿ç”¨ Git_crawler1 çˆ¬å–æ•°æ®")
        return
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    mrs = load_mr_data(args.data_dir)
    
    if len(mrs) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• MR æ•°æ®")
        return
    
    # è¿è¡Œåˆ†æ
    analyze_basic_stats(mrs)
    file_extensions = analyze_code_changes(mrs)
    comment_count, _ = analyze_comments(mrs)
    qa_pairs = analyze_discussions(mrs)
    analyze_titles_descriptions(mrs)
    
    # å»ºè®®ä»»åŠ¡
    suggest_tasks(mrs, file_extensions, comment_count, qa_pairs)
    
    # ä¿å­˜æ ·æœ¬
    save_sample_data(mrs, args.output_dir)
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ!")
    print("=" * 60)


if __name__ == '__main__':
    main()
